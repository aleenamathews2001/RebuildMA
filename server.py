# fastapi_websocket.py
"""
FastAPI WebSocket endpoint for real-time agent communication
"""
import asyncio
import json
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from core.mcp_loader import preload_mcp_tools
from baseagent import get_member_dependency
from graph.marketing_agent import build_marketing_graph
from core.state import MarketingState

import logging

# Load environment variables
load_dotenv()

# ‚úÖ Configure logging to file and console
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("agent.log", mode='a', encoding='utf-8'),
        logging.StreamHandler()
    ],
    force=True
)

app = FastAPI()

 


@app.on_event("startup")
async def startup_event():
    """Pre-load MCP tools on server startup"""
    try:
        logging.info("üöÄ Starting Marketing Agent Server...")
        # Get registry which contains configs for all MCPs
        registry = get_member_dependency("Marketing Agent")
        
        # Filter for valid MCP configs that have executionEndpoint
        service_configs = {}
        for name, data in registry.items():
            if data.get("executionEndpoint"):
                # Adapt config format for loader
                config = {
                    "command": "python", # Default command
                    "args": data.get("executionEndpoint"),
                    "env": None
                }
                # Handle JSON string args 
                if isinstance(config["args"], str):
                    try:
                        config["args"] = json.loads(config["args"])
                    except:
                        config["args"] = [config["args"]]
                        
                service_configs[name] = config
        
        if service_configs:
            await preload_mcp_tools(service_configs)
        else:
            logging.warning("‚ö†Ô∏è No valid MCP configurations found to preload")
            
    except Exception as e:
        logging.error(f"‚ùå Error during startup tool preloading: {e}")

class MessageRequest(BaseModel):
    message: str

class MessageResponse(BaseModel):
    success: bool
    response: str
    iterations: int
    error: str | None = None  # Optional field with default None
    salesforce_data: bool = False

 
@app.websocket("/ws/chat")
async def run_agent(websocket: WebSocket):
    await websocket.accept()  # Accept connection
    
    # üîë Session context: persists across messages (GENERIC for ANY Salesforce object)
    session_context = {
        "created_records": {},         # Generic: {"Campaign": [{Id, Name}, ...], "Contact": [...], "Lead": [...], etc.}
        "conversation_history": []     # Store previous user goals and results
    }
    
    try:
        while True:  # Keep connection open
            # 1. RECEIVE message from client
            data = await websocket.receive_text()
            message_data = json.loads(data)
            user_message = message_data.get("message", "")
            
            # 2. PROCESS the message
            agent_graph = build_marketing_graph()
            
            # üîë Restore shared_result_sets from session (persists campaign, contacts, etc.)
            restored_result_sets = session_context.get("shared_result_sets", {})
            restored_email_content = session_context.get("last_generated_email", None)
            restored_active_workflow = session_context.get("active_workflow", None)

            initial_state: MarketingState = {
                "user_goal": user_message,  # Use received message
                "messages": [],
                "max_iterations": 5,
                "iteration_count": 0,
                # üîë Inject session context into state
                "session_context": session_context.copy(),  # Pass context to the graph
                # üîë Restore shared_result_sets from previous messages in this session
                "shared_result_sets": restored_result_sets.copy() if restored_result_sets else {},
                # üîë Restore generated_email_content (Fix for refinement context)
                "generated_email_content": restored_email_content,
                # üîë Restore active_workflow (Fix for sticky routing)
                "active_workflow": restored_active_workflow
            }
            final_state = await agent_graph.ainvoke(initial_state)
            
            # üîë UPDATE session context with newly created records
            if final_state.get("salesforce_data"):
                sf_data = final_state["salesforce_data"]
                previous_results = sf_data.get("previous_results", [])
                tool_results = sf_data.get("tool_results", [])
                
                logging.info(f"üîç DEBUG: previous_results type: {type(previous_results)}")
                logging.info(f"üîç DEBUG: previous_results count: {len(previous_results) if previous_results else 0}")
                if previous_results:
                    logging.info(f"üîç DEBUG: First previous_result sample: {previous_results[0] if previous_results else 'None'}")

                # Strategy 2: Extract from tool_results (for create/upsert operations) - GENERIC
                if tool_results:
                    for tool_result in tool_results:
                        if tool_result.get("status") != "success":
                            continue
                        
                        tool_name = tool_result.get("tool_name", "")
                        request = tool_result.get("request", {})
                        
                        # Handle ANY object type creation/upsert
                        obj_type = request.get("object_name", "") or request.get("sobject", "")
                        
                        if obj_type:
                            response = tool_result.get("response", {})
                            record_id = None
                            # Get Name field, or use object type if Name doesn't exist
                            record_name = request.get("fields", {}).get("Name") or f"{obj_type} Record"
                            
                            # Parse response to get ID
                            if hasattr(response, 'content'):
                                for item in response.content:
                                    if hasattr(item, 'text'):
                                        try:
                                            parsed = json.loads(item.text)
                                            record_id = parsed.get("id") or parsed.get("Id")
                                        except:
                                            pass
                            # Also check if response is already a dict (direct tool result)
                            elif isinstance(response, dict):
                                record_id = response.get("id") or response.get("Id")
                            
                            if record_id:
                                if obj_type not in session_context["created_records"]:
                                    session_context["created_records"][obj_type] = []
                                
                                record_info = {
                                    "Id": record_id,
                                    "Name": record_name
                                }
                                # Avoid duplicates
                                if not any(r["Id"] == record_id for r in session_context["created_records"][obj_type]):
                                    session_context["created_records"][obj_type].append(record_info)
                                    logging.info(f"üìå Stored {obj_type} from {tool_name}: {record_info}")
        
                # Store conversation history
                session_context["conversation_history"].append({
                    "user_goal": user_message,
                    "result_summary": final_state.get("final_response", "")
                })
            
            # üîë Save shared_result_sets back to session for next message
            if final_state.get("shared_result_sets"):
                session_context["shared_result_sets"] = final_state["shared_result_sets"]
                logging.info(f"üíæ Persisted shared_result_sets to session: {list(final_state['shared_result_sets'].keys())}")
            
            # üîë Save generated_email_content back to session (Fix for refinement context)
            if final_state.get("generated_email_content"):
                session_context["last_generated_email"] = final_state["generated_email_content"]
                logging.info("üíæ Persisted generated_email_content for future refinement.")

            # üîë Save active_workflow back to session (Fix for sticky routing)
            # We explicitly allow it to be None to clear the stickiness
            session_context["active_workflow"] = final_state.get("active_workflow")
            if session_context["active_workflow"]:
                 logging.info(f"üîí Stickiness logic: keeping user in {session_context['active_workflow']}")
            
            # 3. SEND response back to client
            # üîó Use created_records from completion node (has correct IDs/names)
            created_records_from_state = final_state.get("created_records", {})
            logging.info(f"üîó [Server] created_records from state: {created_records_from_state}")
            
            # üî¥ Filter out junction objects (objects without Name field) for UI display
            filtered_records = {}
            # Prefer completion node's created_records (more accurate)
            source_records = created_records_from_state if created_records_from_state else session_context["created_records"]
            logging.info(f"üîó [Server] source_records: {source_records}")
            
            for obj_type, records in source_records.items():
                # Only include records that have an actual Name (not auto-generated)
                main_records = [r for r in records if r.get("Name") and not r["Name"].endswith(" Record")]
                logging.info(f"üîó [Server] {obj_type}: {len(records)} total, {len(main_records)} after filter")
                if main_records:
                    filtered_records[obj_type] = main_records
            
            logging.info(f"üîó [Server] filtered_records to send: {filtered_records}")
            
            final_resp = final_state.get("final_response", "Task completed")
            
            # üöÄ CHECK FOR CONTROL MESSAGES (Review Proposal)
            # If the response is our special JSON, send it RAW so LWC sees type='review_proposal'
            sent_special = False
            if isinstance(final_resp, str) and '"type": "review_proposal"' in final_resp:
                try:
                    control_msg = json.loads(final_resp)
                    # Preserve context if needed, but usually proposal has everything
                    await websocket.send_json(control_msg)
                    sent_special = True
                except Exception as e:
                    logging.error(f"Failed to parse control message: {e}")

            if not sent_special:
                logging.info(f"üì§ [Server] Sending response. Keys in final_state: {list(final_state.keys())}")
                if "generated_email_content" in final_state:
                    logging.info("   ‚úÖ generated_email_content is present in final_state")
                else:
                    logging.warning("   ‚ö†Ô∏è generated_email_content is MISSING from final_state")

                await websocket.send_json({
                    "type": "response",
                    "success": True,
                    "response": final_resp,
                    "iterations": final_state.get("iteration_count", 0),
                    "salesforce_data": bool(final_state.get("salesforce_data")),
                    "created_records": filtered_records,  # Send filtered version to UI
                    "generated_email_content": final_state.get("generated_email_content"), # Sent generated email content to UI
                    "error": final_state.get("error")
                })
            
    except WebSocketDisconnect:
        logging.info("Client disconnected")
    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "message": str(e)
        })

if __name__ == "__main__":
    import uvicorn
    import os
    
    # üìù Print log location for debugging
    log_path = os.path.abspath("agent.log")
    print(f"üìù Logging initialized. File: {log_path}")

    # üöÄ ROBUST LOGGING: Disable Uvicorn's config and attach our handlers manually
    # This prevents Uvicorn from resetting logging settings
    log_config = uvicorn.config.LOGGING_CONFIG
    
    # Run with log_config=None to prevent override
    uvicorn.run(app, host="0.0.0.0", port=8001, log_config=None)

    # Note: Handlers are already attached by logging.basicConfig(force=True) above.
    # Uvicorn loggers (uvicorn, uvicorn.access) will inherit from root logger 
    # if propagation is on (default).
    
    # Explicitly ensure uvicorn loggers use our handlers if needed:
    req_logger = logging.getLogger("uvicorn.access")
    req_logger.handlers = logging.getLogger().handlers 
    err_logger = logging.getLogger("uvicorn.error")
    err_logger.handlers = logging.getLogger().handlers
